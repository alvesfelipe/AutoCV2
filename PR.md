# 厦门大学MAC实验室联合深度赋智在AutoML竞赛获亚军

在近期的ECML PKDD 2019中举办的AutoML类型竞赛AutoCV2中，[厦门大学MAC实验室](http://mac.xmu.edu.cn)联合深度赋智取得了feedback阶段第一名，blind test单项第一，总成绩第二名的佳绩

## 比赛介绍

AutoCV2比赛属于NeurIPS AutoDL系列比赛，由Google，第四范式等在ECML PKDD 2019中举办。比赛的任务是视频/图像的多分类，参赛选手仅需要提交代码，代码会在后台的评测系统上自动进行训练，训练数据集对选手完全未知，需要选手的算法能够完全适应不同的数据集，并且在最短的时间内取得尽可能高的测试精度。

比赛共分为两个阶段，第一个阶段是feedback，参赛选手的代码在后台运行结束后会给出相应的学习曲线的反馈，用于用户调试自己的算法，第二个阶段是blind test，将选手最后提交的代码在另外5个完全未知的数据集进行测试，并且给出最终的结果。

比赛的任务为视频/图像的多分类，并要求每个数据集上的运行时间不超过20分钟。评测指标为每个数据集的学习曲线下的面积（ALC），具体计算方式如下：

- 在每一个时刻t，计算s(t) = Norm AUC = 2 * AUC - 1，s(t)是对时间t的函数

- 将时间归一化到[0,1]区间内，其中的T = 1200s为上限，t0是参考时间，默认为60s

  ![1566902916925](C:\Users\16600\AppData\Roaming\Typora\typora-user-images\1566902916925.png)

- 然后将s(t)在归一化后的时间上进行积分得到ALC

![1566903061074](C:\Users\16600\AppData\Roaming\Typora\typora-user-images\1566903061074.png)

最终我们在feedback阶段的学习曲线如下图

![1566903575656](C:\Users\16600\AppData\Roaming\Typora\typora-user-images\1566903575656.png)

在计算完所有数据集的ALC之后，取所有队伍的平均排名作为选手的最终分数，我们最终取得了feedback第一，blind test单项第一，总成绩第二名的成绩

![1566903702328](C:\Users\16600\AppData\Roaming\Typora\typora-user-images\1566903702328.png)

![1566903825666](C:\Users\16600\AppData\Roaming\Typora\typora-user-images\1566903825666.png)

## 算法简介

我们采用在ImageNet pretrain的ResNet18作为预测模型，为了加速训练过程，我们采用FP16（半精度浮点数）进行训练和测试，算法的核心在于如何在未知数据集的情况下制定最优的数据前处理策略，训练策略，验证策略，数据增强策略以及如何处理各种训练异常情况。

### 数据前处理策略

训练数据集分为图像/视频两种，为了加速视频数据的处理，我们直接将视频数据在时间维度上求平均，用二维卷积来进行处理，相比三维卷积可以在精度损失很小的情况下获取极大的加速。为了减小整体的FLOPS，我们对于所有的输入图像进行resize，并设置最大的resize尺寸为64。为了加速IO，我们选择在数据集较小的时候直接将整个数据集预先加载进显存，这样可以大幅减小IO时间并且提升训练时的gpu利用率。

### 训练策略

学习率的调整策略在训练过程中是至关重要的，然而对于未知的数据集我们需要更加灵活的训练策略来根据训练情况及时作出反应。我们这里使用了warm-up，并根据训练loss来及时对学习率进行衰减。

### 验证策略

在这个比赛中，选择何时进行测试是很重要的，如果测试太频繁则会减小训练的时间，影响最后的精度，测试太少则会取得较小的ALC，因此需要谨慎的选择进行测试的时间。而是否应该进行测试取决于是否在验证集上有较好的性能，如果每一次训练后都在验证集上进行验证则会浪费很多时间，这里我们设置了一定的限制条件来决定是否在这次训练结束之后进行验证，包括训练集精度是否足够/训练时间是否过长/是否进行了连续验证等。

### 数据增强策略

在数据增强中我们选择使用fast autoaugmentation，通过random search的方式来寻找最适合当前数据集的数据增强方式，并且仅在后期训练精度已经足够高的时候才进行数据增强。

### 异常情况处理

对于一些训练中的异常情况，比如训练发散/过拟合等，我们都设置了相应的handler来处理这些异常情况，可以保证面对不同的数据集不会有明显的短板。

